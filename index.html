<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Samaya - Human AI</title>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<style>
  body {
    margin: 0;
    background: #000014;
    color: white;
    font-family: 'Orbitron', sans-serif;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    height: 100vh;
    overflow: hidden;
  }
  .ai-image {
    width: 200px;
    height: 200px;
    border-radius: 50%;
    overflow: hidden;
    border: 4px solid cyan;
    box-shadow: 0 0 25px cyan;
  }
  .ai-image img {
    width: 100%;
    height: 100%;
    object-fit: cover;
  }
  .ai-name {
    margin-top: 20px;
    font-size: 2em;
    color: #00e6e6;
    text-shadow: 0 0 10px #00ffff;
  }
  .chat-box {
    margin-top: 30px;
    width: 90%;
    max-width: 600px;
    background: rgba(0, 255, 255, 0.05);
    border: 1px solid #00ffff66;
    padding: 20px;
    border-radius: 10px;
    min-height: 150px;
    overflow-y: auto;
    font-size: 1rem;
    line-height: 1.5em;
    position: relative;
  }
  .chat-entry {
    margin-bottom: 15px;
  }
  .chat-entry.user {
    text-align: right;
    color: #a0f8f8;
  }
  .chat-entry.ai {
    text-align: left;
    color: #00ffff;
  }
  .mic-btn {
    margin-top: 20px;
    background: #00ffff;
    border: none;
    padding: 10px 25px;
    border-radius: 50px;
    font-size: 1.2em;
    cursor: pointer;
    color: black;
    font-weight: bold;
    box-shadow: 0 0 20px #00ffff;
    transition: 0.3s;
  }
  .mic-btn:hover {
    background: cyan;
    transform: scale(1.05);
  }
  #status {
    margin-top: 10px;
    color: #00ffffaa;
    font-style: italic;
  }
</style>
</head>
<body>

<div class="ai-image">
  <img src="images.jpg" alt="Samaya" />
</div>
<div class="ai-name">SAMAYA</div>
<div class="chat-box" id="chatBox">üëã Tap the mic and speak to Samaya...</div>
<button class="mic-btn" id="micBtn">üéôÔ∏è Speak to Samaya</button>
<div id="status">üéôÔ∏è Ready</div>

<script>
  const chatBox = document.getElementById('chatBox');
  const micBtn = document.getElementById('micBtn');
  const statusText = document.getElementById('status');

  // Setup speech recognition
  let SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  let recognition;
  if (!SpeechRecognition) {
    alert('Sorry, your browser does not support Speech Recognition.');
  } else {
    recognition = new SpeechRecognition();
    recognition.lang = 'en-US';
    recognition.interimResults = false;
    recognition.maxAlternatives = 1;
  }

  // Add chat entry helper
  function addChatEntry(text, sender) {
    const entry = document.createElement('div');
    entry.className = 'chat-entry ' + sender;
    entry.textContent = (sender === 'user' ? 'üó£Ô∏è You: ' : 'ü§ñ Samaya: ') + text;
    chatBox.appendChild(entry);
    chatBox.scrollTop = chatBox.scrollHeight;
    return entry;
  }

  // Sample smarter responses
  function getResponse(message) {
    message = message.toLowerCase();
    if (message.includes("hello") || message.includes("hi")) {
      return "Hello! I'm Samaya, your virtual AI assistant. How can I help you today?";
    }
    if (message.includes("how are you")) {
      return "I'm doing great, thanks for asking! What would you like to talk about?";
    }
    if (message.includes("your name")) {
      return "I am Samaya, your friendly virtual AI companion.";
    }
    if (message.includes("love")) {
      return "Love is a beautiful emotion. I'm here to support you anytime.";
    }
    if (message.includes("sad") || message.includes("alone")) {
      return "I'm sorry you're feeling that way. Remember, you can always talk to me.";
    }
    if (message.includes("thank you")) {
      return "You're very welcome!";
    }
    if (message.includes("bye") || message.includes("goodbye")) {
      return "Goodbye! Have a wonderful day!";
    }
    return "That's interesting. Tell me more or ask me something else!";
  }

  // Typewriter effect for AI replies
  function typeReply(text, element) {
    return new Promise(resolve => {
      let i = 0;
      element.textContent = '';
      function type() {
        if (i < text.length) {
          element.textContent += text.charAt(i);
          i++;
          setTimeout(type, 40);
        } else {
          resolve();
        }
      }
      type();
    });
  }

  // Speech synthesis wrapper
  function speak(text) {
    return new Promise(resolve => {
      const synth = window.speechSynthesis;
      if (synth.speaking) {
        synth.cancel();
      }

      let voices = synth.getVoices();
      if (!voices.length) {
        synth.onvoiceschanged = () => {
          voices = synth.getVoices();
          speakWithVoice(text, voices, resolve);
        };
      } else {
        speakWithVoice(text, voices, resolve);
      }
    });
  }

  function speakWithVoice(text, voices, resolve) {
    const utter = new SpeechSynthesisUtterance(text);
    // Use English Google voice if available, else default
    const voice = voices.find(v => v.lang.startsWith('en') && v.name.toLowerCase().includes('google')) || voices[0];
    utter.voice = voice;
    utter.pitch = 1.1;
    utter.rate = 0.95;
    utter.volume = 1;
    utter.onend = resolve;
    utter.onerror = resolve;
    window.speechSynthesis.speak(utter);
  }

  // Listen button click
  micBtn.addEventListener('click', () => {
    if (!recognition) return;
    micBtn.disabled = true;
    statusText.textContent = "üéß Listening...";
    recognition.start();
  });

  // Recognition event handlers
  if (recognition) {
    recognition.onresult = async (event) => {
      const userInput = event.results[0][0].transcript;
      addChatEntry(userInput, 'user');
      statusText.textContent = "ü§ñ Thinking...";

      const reply = getResponse(userInput);
      const aiEntry = addChatEntry("", 'ai');
      await typeReply(reply, aiEntry);
      await speak(reply);

      statusText.textContent = "üéôÔ∏è Ready";
      micBtn.disabled = false;
    };

    recognition.onerror = (event) => {
      statusText.textContent = "‚ùå Error: " + event.error;
      micBtn.disabled = false;
    };

    recognition.onend = () => {
      // Enable mic if it ended without error
      if (!micBtn.disabled) statusText.textContent = "üéôÔ∏è Ready";
    };
  }

  // Initial greeting on page load
  window.onload = async () => {
    statusText.textContent = "üéôÔ∏è Ready";
    const welcome = "Hello! I am Samaya, your virtual assistant. Tap the microphone and ask me anything.";
    const aiEntry = addChatEntry("", 'ai');
    await typeReply(welcome, aiEntry);
    await speak(welcome);
  };
</script>

</body>
</html>
